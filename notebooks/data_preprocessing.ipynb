{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), make_column_selector(dtype_exclude=['object', 'category'])),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output = False), make_column_selector(dtype_include=['object', 'category']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_159800/1448577990.py:2: FutureWarning: Support for `output_format` of 'dict' will be removed in 0.15 and pandas dataframes will be returned instead. To ensure your code will continue to work, use `output_format`='dataframe'.\n",
      "  for i, (key, item) in enumerate(openml.datasets.list_datasets(tag='OpenML-CC18').items()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  kr-vs-kp\n",
      "1:  letter\n",
      "2:  balance-scale\n",
      "3:  mfeat-factors\n",
      "4:  mfeat-fourier\n",
      "5:  breast-w\n",
      "6:  mfeat-karhunen\n",
      "7:  mfeat-morphological\n",
      "8:  mfeat-zernike\n",
      "9:  cmc\n",
      "10:  optdigits\n",
      "11:  credit-approval\n",
      "12:  credit-g\n",
      "13:  pendigits\n",
      "14:  diabetes\n",
      "15:  sick\n",
      "16:  spambase\n",
      "17:  splice\n",
      "18:  tic-tac-toe\n",
      "19:  vehicle\n",
      "20:  electricity\n",
      "21:  satimage\n",
      "22:  eucalyptus\n",
      "23:  isolet\n",
      "24:  vowel\n",
      "25:  analcatdata_authorship\n",
      "26:  analcatdata_dmft\n",
      "27:  mnist_784\n",
      "28:  pc4\n",
      "29:  pc3\n",
      "30:  jm1\n",
      "31:  kc2\n",
      "32:  kc1\n",
      "33:  pc1\n",
      "34:  bank-marketing\n",
      "35:  banknote-authentication\n",
      "36:  blood-transfusion-service-center\n",
      "37:  cnae-9\n",
      "38:  first-order-theorem-proving\n",
      "39:  har\n",
      "40:  ilpd\n",
      "41:  madelon\n",
      "42:  nomao\n",
      "43:  ozone-level-8hr\n",
      "44:  phoneme\n",
      "45:  qsar-biodeg\n",
      "46:  wall-robot-navigation\n",
      "47:  semeion\n",
      "48:  wdbc\n",
      "49:  adult\n",
      "50:  Bioresponse\n",
      "51:  PhishingWebsites\n",
      "52:  GesturePhaseSegmentationProcessed\n",
      "53:  cylinder-bands\n",
      "54:  dresses-sales\n",
      "55:  numerai28.6\n",
      "56:  texture\n",
      "57:  connect-4\n",
      "58:  dna\n",
      "59:  churn\n",
      "60:  Devnagari-Script\n",
      "61:  CIFAR_10\n",
      "62:  MiceProtein\n",
      "63:  car\n",
      "64:  Internet-Advertisements\n",
      "65:  mfeat-pixel\n",
      "66:  steel-plates-fault\n",
      "67:  wilt\n",
      "68:  segment\n",
      "69:  climate-model-simulation-crashes\n",
      "70:  Fashion-MNIST\n",
      "71:  jungle_chess_2pcs_raw_endgame_complete\n",
      "72:  JapaneseVowels\n"
     ]
    }
   ],
   "source": [
    "shapes = []\n",
    "for i, (key, item) in enumerate(openml.datasets.list_datasets(tag='OpenML-CC18').items()):\n",
    "    print(f\"{i}:  {item['name']}\")\n",
    "    if item['name'] not in ('CIFAR_10', 'Devnagari-Script', 'Fashion-MNIST', 'mnist_784'):\n",
    "\n",
    "        data = fetch_openml(data_id = item['did'])\n",
    "        X = data['data']\n",
    "        y = data['target']\n",
    "\n",
    "        feature_names = data['feature_names']\n",
    "        target_names = data['target_names']\n",
    "\n",
    "        df = pd.concat([X, y], axis = 1)\n",
    "        df = df.rename(columns = {data['target_names'][0]: 'y_target_class'})\n",
    "        df = df.dropna()\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        if df.shape[0] > 0:\n",
    "            label_encoder = LabelEncoder()\n",
    "            df['y_target_class'] = label_encoder.fit_transform(df['y_target_class'])\n",
    "\n",
    "            X_transformed = preprocessor.fit_transform(df.drop(columns=['y_target_class']))\n",
    "            y_transformed = df['y_target_class']\n",
    "\n",
    "            df = pd.concat([pd.DataFrame(X_transformed), y_transformed], axis = 1)\n",
    "\n",
    "            df.to_csv(f\"../data/CC18/{item['name']}.csv\", index = False)\n",
    "\n",
    "            shapes.append(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/synth_moa_arff'\n",
    "datasets_arff = sorted(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10: HyperplaneFaster.arff\n",
      "2/10: HyperplaneSlow.arff\n",
      "3/10: LED.arff\n",
      "4/10: LEDNoDrift.arff\n",
      "5/10: RBFBlips.arff\n",
      "6/10: RBFGradualRecurring.arff\n",
      "7/10: RBFNoDrift.arff\n",
      "8/10: RandomTreeRecurring.arff\n",
      "9/10: SEASudden.arff\n",
      "10/10: SEASuddenFaster.arff\n"
     ]
    }
   ],
   "source": [
    "for i,dataset in enumerate(datasets_arff):\n",
    "    print(f'{i+1}/10: {dataset}')\n",
    "    data = loadarff(f'{data_path}/{dataset}')\n",
    "    df = pd.DataFrame(data[0])\n",
    "\n",
    "    X = df.drop(columns=['class'])\n",
    "    y = df['class']\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_transformed = label_encoder.fit_transform(y)\n",
    "\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(X_transformed), pd.Series(y_transformed, name = 'class')], axis = 1)\n",
    "\n",
    "    df.to_csv(f\"../data/synth_moa_csv/{dataset[:-5]}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/real_moa_arff'\n",
    "datasets_arff = sorted(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4: airlines.arff\n",
      "2/4: covtypeNorm.arff\n",
      "3/4: elecNormNew.arff\n",
      "4/4: poker-lsn.arff\n"
     ]
    }
   ],
   "source": [
    "target_class = {\n",
    "    'airlines.arff': 'Delay',\n",
    "    'covtypeNorm.arff': 'class',\n",
    "    'elecNormNew.arff': 'class',\n",
    "    'poker-lsn.arff': 'class'\n",
    "}\n",
    "\n",
    "for i,dataset in enumerate(datasets_arff):\n",
    "    print(f'{i+1}/4: {dataset}')\n",
    "    data = loadarff(f'{data_path}/{dataset}')\n",
    "    df = pd.DataFrame(data[0])\n",
    "\n",
    "    X = df.drop(columns=[target_class[dataset]])\n",
    "    y = df[target_class[dataset]]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_transformed = label_encoder.fit_transform(y)\n",
    "\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(X_transformed), pd.Series(y_transformed, name = 'class')], axis = 1)\n",
    "\n",
    "    df.to_csv(f\"../data/real_moa_csv/{dataset[:-5]}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
